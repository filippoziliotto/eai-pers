# Debugging stuff
debugger:
  debug: true

# Baseline
baseline:
    use_baseline: false
    type: "zs_cosine"

logging:
  wandb:
    use_wandb: false
    run_name: "eai_pers"

training:
  mode: "train"
  num_epochs: 100
  batch_size: 2     
  loss:
    choice: "Huber+CE"

attention:
  num_heads: 4

encoder:
  freeze: true
  lora:
    use_lora: false

model:
  fs:
    use_pos_embed: true              # Use positional embeddings
    num_cross_layers: 1          # Number of cross-attention layers
  ss:
    type: "base"                     # Model architecture variant
    tau_config:
      tau: [0.1, 0.5]                         # Softmax/contrastive temperature
      step: 20
      
augmentations:
  flip:
    use_horizontal_flip: true
    use_vertical_flip: true
    prob: 0.5
  crop:
    use_crop: true
    prob: 0.5
  rotation:
    use_rotation: true   
    prob: 0.5

device:
  type: "mps"
  num_workers: 4

optimizer:
  type: "adam"
  lr: 0.001 
  weight_decay: 1e-3

scheduler:
  type: "none"
  step_size: 5
  gamma: 0.1
  patience: 10